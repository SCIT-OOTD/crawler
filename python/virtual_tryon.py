import os
import json
import torch
import cv2
import numpy as np
import requests
from PIL import Image
from io import BytesIO
from diffusers import AutoPipelineForInpainting
from diffusers.utils import load_image

# ==========================================
# 1. ì„¤ì • (Configuration)
# ==========================================
# ì €ì¥ëœ JSON íŒŒì¼ ê²½ë¡œ (ë˜ëŠ” DB ì—°ê²° ì •ë³´ë¥¼ ì“°ì…”ë„ ë©ë‹ˆë‹¤)
DATA_FILE = 'twentynine_ai_data.json'
OUTPUT_DIR = 'tryon_results'
os.makedirs(OUTPUT_DIR, exist_ok=True)

# ëª¨ë¸ ID (CatVTON ê¸°ë°˜ ë˜ëŠ” í˜¸í™˜ë˜ëŠ” ì¸í˜ì¸íŒ… ëª¨ë¸ ì‚¬ìš©)
# CatVTON ì „ìš© íŒŒì´í”„ë¼ì¸ì€ ë³µì¡í•˜ë¯€ë¡œ, ê°€ì¥ ìœ ì‚¬í•œ ê³ ì„±ëŠ¥ ì¸í˜ì¸íŒ… ëª¨ë¸ì„ ë¨¼ì € ì˜ˆì‹œë¡œ ë“­ë‹ˆë‹¤.
# ì‹¤ì œ CatVTON ê°€ì¤‘ì¹˜ë¥¼ ì“°ë ¤ë©´ ì „ìš© repoë¥¼ cloneí•´ì•¼ í•˜ë¯€ë¡œ, ì—¬ê¸°ì„  diffusers í‘œì¤€ ë°©ì‹ìœ¼ë¡œ êµ¬í˜„í•©ë‹ˆë‹¤.
MODEL_ID = "kandinsky-community/kandinsky-2-2-decoder-inpaint" # í˜¹ì€ CatVTON ê²½ë¡œ

# ==========================================
# 2. ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜
# ==========================================
def download_image(url):
    """URLì—ì„œ ì´ë¯¸ì§€ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ì—¬ PIL í¬ë§·ìœ¼ë¡œ ë³€í™˜"""
    response = requests.get(url)
    return Image.open(BytesIO(response.content)).convert("RGB")

def create_upper_body_mask(image_pil):
    """
    [í•µì‹¬] ì˜·ì„ ì…í ì˜ì—­(Mask)ì„ ìë™ìœ¼ë¡œ ë§Œë“­ë‹ˆë‹¤.
    ì›ë˜ëŠ” 'Segmentation' ëª¨ë¸ì„ ì¨ì•¼ í•˜ì§€ë§Œ, ì—¬ê¸°ì„  í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´
    ì´ë¯¸ì§€ì˜ ì¤‘ì•™ ë¶€ë¶„ì„ ë§ˆìŠ¤í¬ë¡œ ì¡ëŠ” ê°„ë‹¨í•œ ë°©ì‹ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
    """
    w, h = image_pil.size
    mask = np.zeros((h, w), dtype=np.uint8)

    # ì˜ˆì‹œ: ìƒì²´ ë¶€ë¶„(ìœ„ì—ì„œ 15%~60% ì§€ì )ì— ë„¤ëª¨ë‚œ êµ¬ë©ì„ ëš«ìŒ
    # ì‹¤ì œ ì„œë¹„ìŠ¤ì—ì„  'DensePose'ë‚˜ 'Human Parsing' AIë¥¼ ì¨ì•¼ ì •í™•í•©ë‹ˆë‹¤.
    cv2.rectangle(mask, (int(w*0.2), int(h*0.15)), (int(w*0.8), int(h*0.6)), 255, -1)

    return Image.fromarray(mask)

# ==========================================
# 3. ë©”ì¸ ë¡œì§
# ==========================================
def run_virtual_tryon():
    print(">> [1] ëª¨ë¸ ë¡œë”© ì¤‘... (GPU í•„ìš”)")
    try:
        # GPU ì‚¬ìš© ì„¤ì •
        device = "cuda" if torch.cuda.is_available() else "cpu"
        dtype = torch.float16 if device == "cuda" else torch.float32

        # íŒŒì´í”„ë¼ì¸ ë¡œë“œ (ì²˜ìŒ ì‹¤í–‰ ì‹œ ëª‡ ê¸°ê°€ë°”ì´íŠ¸ ë‹¤ìš´ë¡œë“œí•¨)
        pipe = AutoPipelineForInpainting.from_pretrained(
            "diffusers/stable-diffusion-xl-1.0-inpainting-0.1",
            torch_dtype=dtype,
            variant="fp16" if device == "cuda" else None
        ).to(device)
        print(f">> ëª¨ë¸ ë¡œë”© ì™„ë£Œ (Device: {device})")

    except Exception as e:
        print(f"ğŸš¨ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
        print("GPU ë©”ëª¨ë¦¬ê°€ ë¶€ì¡±í•˜ê±°ë‚˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë²„ì „ ë¬¸ì œì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        return

    # ë°ì´í„° ë¡œë“œ
    with open(DATA_FILE, 'r', encoding='utf-8') as f:
        products = json.load(f)

    if not products:
        print("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    # ì²« ë²ˆì§¸ ìƒí’ˆìœ¼ë¡œ í…ŒìŠ¤íŠ¸
    item = products[0]
    print(f">> [2] ì²˜ë¦¬í•  ìƒí’ˆ: {item['title']}")

    try:
        # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
        model_img = download_image(item['model_img']) # ì‚¬ëŒ
        cloth_img = download_image(item['cloth_img']) # ì˜·

        # ì´ë¯¸ì§€ í¬ê¸° ì¡°ì • (512x512, 1024x1024 ë“± 8ì˜ ë°°ìˆ˜ì—¬ì•¼ í•¨)
        model_img = model_img.resize((1024, 1024))
        cloth_img = cloth_img.resize((1024, 1024))

        # ë§ˆìŠ¤í¬ ìƒì„± (ì˜·ì„ ì…í ìœ„ì¹˜)
        mask_img = create_upper_body_mask(model_img)

        # ê²°ê³¼ ì €ì¥ í™•ì¸ìš©
        model_img.save(os.path.join(OUTPUT_DIR, "input_person.jpg"))
        cloth_img.save(os.path.join(OUTPUT_DIR, "input_cloth.jpg"))
        mask_img.save(os.path.join(OUTPUT_DIR, "input_mask.jpg"))

        print(">> [3] ê°€ìƒ í”¼íŒ… ìƒì„± ì‹œì‘ (ì•½ 10~30ì´ˆ ì†Œìš”)...")

        # í”„ë¡¬í”„íŠ¸ ìƒì„± (ì˜·ì˜ íŠ¹ì§•ì„ í…ìŠ¤íŠ¸ë¡œë„ ì¤Œ)
        prompt = f"A photo of a model wearing {item['title']}, high quality, photorealistic"

        # ì¶”ë¡  ì‹¤í–‰
        # (ì°¸ê³ : CatVTON ì „ìš© íŒŒì´í”„ë¼ì¸ì€ cloth_imageë¥¼ ë³„ë„ ì…ë ¥ìœ¼ë¡œ ë°›ì§€ë§Œ,
        # ì¼ë°˜ ì¸í˜ì¸íŒ… ëª¨ë¸ì€ í…ìŠ¤íŠ¸+ë§ˆìŠ¤í¬ ê¸°ë°˜ì´ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” ê°œë…ì  êµ¬í˜„ì…ë‹ˆë‹¤.)
        image = pipe(
            prompt=prompt,
            image=model_img,
            mask_image=mask_img,
            num_inference_steps=30,
            strength=0.99, # ë§ˆìŠ¤í¬ ì˜ì—­ì„ ì–¼ë§ˆë‚˜ ë§ì´ ë°”ê¿€ì§€ (0.99 = ì™„ì „íˆ êµì²´)
            guidance_scale=7.5
        ).images[0]

        # ê²°ê³¼ ì €ì¥
        save_path = os.path.join(OUTPUT_DIR, f"result_{item['product_no']}.png")
        image.save(save_path)
        print(f"âœ… ìƒì„± ì™„ë£Œ! ì €ì¥ë¨: {save_path}")

    except Exception as e:
        print(f"ğŸš¨ ì—ëŸ¬ ë°œìƒ: {e}")

if __name__ == "__main__":
    run_virtual_tryon()