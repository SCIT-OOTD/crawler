from playwright.sync_api import sync_playwright
import json
import sys
import io
import time
import re

sys.stdout = io.TextIOWrapper(sys.stdout.detach(), encoding='utf-8')
sys.stderr = io.TextIOWrapper(sys.stderr.detach(), encoding='utf-8')

def parse_korean_number(text):
    if not text: return 0
    text = str(text).strip()
    text = text.replace(',', '')
    multiplier = 1
    if 'ë§Œ' in text:
        multiplier = 10000
        text = text.replace('ë§Œ', '')
    elif 'ì²œ' in text:
        multiplier = 1000
        text = text.replace('ì²œ', '')
    clean_num = re.sub(r"[^0-9.]", "", text)
    if clean_num:
        try:
            return int(float(clean_num) * multiplier)
        except:
            return 0
    return 0

def run():
    results = []
    # ëž­í‚¹ íŽ˜ì´ì§€
    RANKING_URL = "https://www.musinsa.com/main/musinsa/ranking?gf=A"

    print(">> [ë¬´ì‹ ì‚¬] íŒ¨í„´ ë§¤ì¹­ í¬ë¡¤ë§ ì‹œìž‘...")

    with sync_playwright() as p:
        browser = p.chromium.launch(headless=False) # ë¸Œë¼ìš°ì € ëœ¨ëŠ”ê±° í™•ì¸
        context = browser.new_context(viewport={"width": 1920, "height": 1080})
        page = context.new_page()

        # 1. ëž­í‚¹ ì§„ìž…
        page.goto(RANKING_URL, timeout=60000)
        time.sleep(3)

        # 2. ë§í¬ ìˆ˜ì§‘
        items_data = page.evaluate("""() => {
            const data = [];
            const links = Array.from(document.querySelectorAll("a"));
            const productLinks = links.filter(a => 
                (a.href.includes('/goods/') || a.href.includes('/products/')) && 
                !a.href.includes('reviews')
            );
            productLinks.slice(0, 15).forEach(a => {
               data.push({ href: a.href }); 
            });
            return data;
        }""")

        # ì¤‘ë³µ ì œê±°
        target_items = []
        seen = set()
        for item in items_data:
            url = item['href'].split('?')[0]
            if url not in seen:
                seen.add(url)
                target_items.append(item)
            if len(target_items) >= 10: break

        print(f">> ìˆ˜ì§‘ ëŒ€ìƒ: {len(target_items)}ê°œ")

        # 3. ìƒì„¸ íŽ˜ì´ì§€ ìˆœíšŒ
        for idx, item in enumerate(target_items):
            try:
                print(f">> [{idx+1}] ì ‘ì†: {item['href']}")
                page.goto(item['href'], timeout=60000)

                # ðŸ”¥ [ì¤‘ìš”] ë°ì´í„° ë¡œë”© ëŒ€ê¸° (ì¢‹ì•„ìš”/í›„ê¸° ë¡œë”© ì‹œê°„ ì¤Œ)
                time.sleep(4)

                # ìŠ¤í¬ë¡¤ ì‚´ì§ ë‚´ë ¤ì„œ ì´ë¯¸ì§€/ë°ì´í„° ë¡œë”© ìœ ë„
                page.mouse.wheel(0, 1000)
                time.sleep(1)

                # ---------------------------------------------------
                # ðŸ•µï¸â€â™€ï¸ 1. ê¸°ë³¸ ì •ë³´ (ë©”íƒ€íƒœê·¸ - ê°€ìž¥ ì •í™•í•¨)
                # ---------------------------------------------------
                meta_info = page.evaluate("""() => {
                    const getMeta = (prop) => {
                        const el = document.querySelector(`meta[property="${prop}"]`);
                        return el ? el.content : "";
                    };
                    return {
                        brand: getMeta('product:brand'),
                        title: getMeta('og:title'),
                        price: getMeta('product:price:amount'),
                        img: getMeta('og:image')
                    };
                }""")

                # ---------------------------------------------------
                # ðŸ•µï¸â€â™€ï¸ 2. í†µê³„ ì •ë³´ (ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ ì •ê·œì‹ìœ¼ë¡œ ì¶”ì¶œ)
                # ---------------------------------------------------
                # íŽ˜ì´ì§€ì˜ ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ ê°€ì ¸ì™€ì„œ íŒŒì´ì¬ì—ì„œ ë¶„ì„í•©ë‹ˆë‹¤.
                full_text = page.evaluate("document.body.innerText")

                # (1) ì¢‹ì•„ìš” ì°¾ê¸°
                # íŒ¨í„´: ì¤„ë°”ê¿ˆ í˜¹ì€ ê³µë°± ë’¤ì— ìˆ«ìž+ë§Œ/ì²œ íŒ¨í„´ì´ ìžˆëŠ”ì§€ í™•ì¸
                # ë¬´ì‹ ì‚¬ ì¢‹ì•„ìš”ëŠ” ë³´í†µ í•˜íŠ¸ ì•„ì´ì½˜ ê·¼ì²˜ì— ìžˆì§€ë§Œ í…ìŠ¤íŠ¸ë¡œëŠ” ìˆ«ìžë§Œ ë©ê·¸ëŸ¬ë‹ˆ ìžˆëŠ” ê²½ìš°ê°€ ë§ŽìŒ
                # ì •í™•ë„ë¥¼ ìœ„í•´ 'ì¢‹ì•„ìš”' í…ìŠ¤íŠ¸ê°€ í¬í•¨ëœ ë²„íŠ¼ì˜ í…ìŠ¤íŠ¸ë¥¼ ìš°ì„ ì ìœ¼ë¡œ ê°€ì ¸ì˜¤ë„ë¡ JS ì‹¤í–‰
                like_raw = page.evaluate("""() => {
                    // 1. 'ì¢‹ì•„ìš”' ë‹¨ì–´ê°€ í¬í•¨ëœ ìš”ì†Œ ì°¾ê¸°
                    const likes = Array.from(document.querySelectorAll('*'))
                        .filter(el => el.innerText && el.innerText.includes('ì¢‹ì•„ìš”') && el.innerText.length < 30)
                        .map(el => el.innerText);
                    
                    // 2. ë§Œì•½ ì—†ë‹¤ë©´ classì— likeê°€ ë“¤ì–´ê°„ ìš”ì†Œì˜ ìˆ«ìž ì°¾ê¸°
                    if (likes.length === 0) {
                         const likeClass = Array.from(document.querySelectorAll('[class*="like"]'))
                            .filter(el => el.innerText && el.innerText.match(/[0-9]/) && el.innerText.length < 10)
                            .map(el => el.innerText);
                         return likeClass[0] || "0";
                    }
                    return likes[0] || "0";
                }""")

                # (2) ë³„ì  ì°¾ê¸° (í…ìŠ¤íŠ¸ì—ì„œ "4.8" "4.9" ê°™ì€ íŒ¨í„´ ì°¾ê¸°)
                # â˜… ëª¨ì–‘ì´ ìžˆê±°ë‚˜ ì ìˆ˜ê°€ ìžˆëŠ” íŒ¨í„´
                rating = 0.0
                rating_match = re.search(r'([3-5])\.([0-9])', full_text) # 3.0 ~ 5.9 ì‚¬ì´ ìˆ«ìž ê²€ìƒ‰
                if rating_match:
                    rating = float(rating_match.group(0))

                # (3) í›„ê¸° ìˆ˜ ì°¾ê¸° ("í›„ê¸° 1,234" ë˜ëŠ” "í›„ê¸° 1.2ë§Œ")
                review_cnt = 0
                # "í›„ê¸°" ë¼ëŠ” ê¸€ìž ë’¤ì— ë‚˜ì˜¤ëŠ” ìˆ«ìž ì°¾ê¸°
                review_match = re.search(r'í›„ê¸°\s*([0-9,ë§Œì²œ]+)', full_text)
                if review_match:
                    review_cnt = parse_korean_number(review_match.group(1))
                else:
                    # ëª» ì°¾ì•˜ìœ¼ë©´ ìˆ«ìž+ê°œ íŒ¨í„´ ("2,392ê°œ")
                    review_match2 = re.search(r'([0-9,]+)ê°œ', full_text)
                    if review_match2:
                        review_cnt = parse_korean_number(review_match2.group(1))

                # --- ë°ì´í„° ì •ë¦¬ ---
                price = int(float(meta_info['price'])) if meta_info['price'] else 0
                brand = meta_info['brand'] if meta_info['brand'] else "ë¬´ì‹ ì‚¬"
                title = meta_info['title'] if meta_info['title'] else "ì œëª© ì—†ìŒ"

                # ì¢‹ì•„ìš” ìˆ«ìž ì •ì œ
                like_cnt = parse_korean_number(like_raw)

                # í›„ê¸°ê°€ 0ì´ë©´ í˜¹ì‹œ ëª¨ë¥´ë‹ˆ ratingë„ ì˜ì‹¬ (ë‘˜ ë‹¤ ì—†ìœ¼ë©´ ì‹ ìƒí’ˆì¼ìˆ˜ë„)
                if review_cnt == 0 and rating == 0:
                    # ì•ˆì „ìž¥ì¹˜: ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ (123) ì²˜ëŸ¼ ê´„í˜¸ ì•ˆ ìˆ«ìž ì°¾ê¸° (ëŒ“ê¸€ìˆ˜ì¼ í™•ë¥  ë†’ìŒ)
                    backup_match = re.search(r'\(([0-9,]+)\)', full_text)
                    if backup_match:
                        review_cnt = parse_korean_number(backup_match.group(1))

                data = {
                    "ranking": idx + 1,
                    "brand": brand,
                    "title": title,
                    "price": price,
                    "imgUrl": meta_info['img'],
                    "subImgUrl": meta_info['img'],
                    "category": "ì˜ë¥˜",
                    "likeCount": like_cnt,
                    "rating": rating,
                    "reviewCount": review_cnt
                }

                results.append(data)
                print(f"   -> [í™•ì¸] â¤ï¸{like_cnt} | â˜…{rating} | ðŸ“{review_cnt} | {title[:10]}")

            except Exception as e:
                print(f"   -> âŒ ì—ëŸ¬: {e}")

        browser.close()

    print(f">> ìµœì¢… {len(results)}ê±´ ì €ìž¥.")
    with open("python/musinsa_data.json", "w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=4)

if __name__ == "__main__":
    run()