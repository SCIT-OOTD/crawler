from playwright.sync_api import sync_playwright
import sys
import time
import re
import pymysql

# 1. DB ì„¤ì • (ë„ì»¤ ì»¨í…Œì´ë„ˆ ì´ë¦„ í™•ì¸ í•„ìˆ˜!)
db_config = {
    'host': 'ootd-db',   # docker-composeì˜ ì„œë¹„ìŠ¤ ì´ë¦„
    'user': 'root',
    'password': '1234',  # docker-composeì˜ MYSQL_ROOT_PASSWORDì™€ ì¼ì¹˜í•´ì•¼ í•¨
    'database': 'musinsa_db',
    'port': 3306,
    'charset': 'utf8mb4',
    'cursorclass': pymysql.cursors.DictCursor
}

def parse_korean_number(text):
    if not text: return 0
    text = str(text).strip()
    multiplier = 1
    if 'ë§Œ' in text:
        multiplier = 10000
        text = text.replace('ë§Œ', '')
    elif 'ì²œ' in text:
        multiplier = 1000
        text = text.replace('ì²œ', '')
    clean_num = re.sub(r"[^0-9.]", "", text)
    if clean_num:
        try:
            return int(float(clean_num) * multiplier)
        except:
            return 0
    return 0

def scrape_musinsa():
    total_results = []
    # ì¹´í…Œê³ ë¦¬ë³„ URL ì •ì˜
    CATEGORY_URLS = {
        "ìƒì˜": "https://www.musinsa.com/main/musinsa/ranking?gf=A&storeCode=musinsa&sectionId=200&categoryCode=001000",
        "í•˜ì˜": "https://www.musinsa.com/main/musinsa/ranking?gf=A&storeCode=musinsa&sectionId=200&categoryCode=003000",
        "ì‹ ë°œ": "https://www.musinsa.com/main/musinsa/ranking?gf=A&storeCode=musinsa&sectionId=200&categoryCode=005000",
        "ì•„ìš°í„°": "https://www.musinsa.com/main/musinsa/ranking?gf=A&storeCode=musinsa&sectionId=200&categoryCode=002000"
    }

    print(">> [ë¬´ì‹ ì‚¬] í†µí•© í¬ë¡¤ë§ ì‹œì‘...", flush=True)

    # [ì¤‘ìš”] with êµ¬ë¬¸ ì•ˆì—ì„œ ëª¨ë“  ë¸Œë¼ìš°ì € ì‘ì—…ì´ ì´ë£¨ì–´ì ¸ì•¼ í•¨
    with sync_playwright() as p:
        # âš ï¸ Dockerì—ì„œëŠ” ë°˜ë“œì‹œ headless=True ì—¬ì•¼ í•©ë‹ˆë‹¤!
        browser = p.chromium.launch(headless=True)
        page = browser.new_page()

        for cat_name, cat_url in CATEGORY_URLS.items():
            print(f"\n>> ğŸš€ [{cat_name}] ìˆ˜ì§‘ ì‹œì‘...", flush=True)
            try:
                page.goto(cat_url, timeout=60000)
                time.sleep(2)

                # ìŠ¤í¬ë¡¤ ë‚´ë¦¬ê¸° (ë°ì´í„° ë¡œë”©)
                for _ in range(3): 
                    page.keyboard.press("PageDown")
                    time.sleep(1)
                
                # ìƒí’ˆ ë§í¬ ê°€ì ¸ì˜¤ê¸°
                items_data = page.evaluate("""() => {
                    const data = [];
                    const links = Array.from(document.querySelectorAll("a"));
                    const productLinks = links.filter(a => 
                        (a.href.includes('/goods/') || a.href.includes('/products/')) && 
                        !a.href.includes('reviews')
                    );
                    // í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ 5ê°œë§Œ ìˆ˜ì§‘
                    productLinks.slice(0, 5).forEach(a => { data.push({ href: a.href }); });
                    return data;
                }""")

                # ì¤‘ë³µ ì œê±°
                target_items = []
                seen = set()
                for item in items_data:
                    url = item['href'].split('?')[0]
                    if url not in seen:
                        seen.add(url)
                        target_items.append(item)

                # ìƒì„¸ í˜ì´ì§€ ì´ë™ ë° ë°ì´í„° ì¶”ì¶œ
                for idx, item in enumerate(target_items):
                    try:
                        page.goto(item['href'], timeout=60000)
                        time.sleep(1) 

                        extracted = page.evaluate("""() => {
                            const getMeta = (p) => document.querySelector(`meta[property="${p}"]`)?.content || "";
                            return {
                                title: getMeta('og:title'),
                                brand: getMeta('product:brand'),
                                img: getMeta('og:image'),
                                price: getMeta('product:price:amount')
                            };
                        }""")

                        price_int = int(extracted['price']) if extracted['price'] else 0
                        
                        data = {
                            "ranking": idx + 1,
                            "brand": extracted['brand'] if extracted['brand'] else "ë¬´ì‹ ì‚¬",
                            "title": extracted['title'],
                            "price": price_int,
                            "img_url": extracted['img'],
                            "category": cat_name,
                            "link": item['href'],
                            "like_count": 0,
                            "rating": 0.0,
                            "review_count": 0,
                            "view_count": 0
                        }
                        total_results.append(data)
                        print(f"  - ìˆ˜ì§‘ì„±ê³µ: {data['title'][:15]}...")

                    except Exception as e:
                        print(f"  - ê°œë³„ ìƒí’ˆ ì—ëŸ¬: {e}")
            
            except Exception as e:
                print(f"[{cat_name}] ì¹´í…Œê³ ë¦¬ ì—ëŸ¬: {e}")

        browser.close()
    
    return total_results

# [ìˆ˜ì •ë¨] DB ì—°ê²°ì´ ë  ë•Œê¹Œì§€ ê¸°ë‹¤ë¦¬ëŠ” ì•ˆì „í•œ ì´ˆê¸°í™” í•¨ìˆ˜
def init_db():
    retries = 30  # 30ë²ˆ ì‹œë„ (ì•½ 90ì´ˆ ëŒ€ê¸°)
    while retries > 0:
        try:
            print(f">> DB ì ‘ì† ì‹œë„ ì¤‘... (ë‚¨ì€ ì‹œë„: {retries})")
            conn = pymysql.connect(**db_config)
            cursor = conn.cursor()
            
            # í…Œì´ë¸” ìƒì„± ì¿¼ë¦¬
            create_table_sql = """
            CREATE TABLE IF NOT EXISTS musinsa_item (
                id INT AUTO_INCREMENT PRIMARY KEY,
                title VARCHAR(255),
                brand VARCHAR(100),
                price INT,
                img_url TEXT,
                category VARCHAR(50),
                link TEXT,
                ranking INT,
                like_count INT DEFAULT 0,
                rating FLOAT DEFAULT 0.0,
                review_count INT DEFAULT 0,
                view_count INT DEFAULT 0,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            );
            """
            cursor.execute(create_table_sql)
            conn.commit()
            print(">> âœ… DB ì—°ê²° ë° í…Œì´ë¸” í™•ì¸ ì™„ë£Œ! (ì„±ê³µ)")
            conn.close()
            return  # ì„±ê³µí•˜ë©´ í•¨ìˆ˜ ì¢…ë£Œ
            
        except pymysql.err.OperationalError as e:
            # DBê°€ ì¼œì§€ëŠ” ì¤‘ì´ë¼ ì ‘ì†ì´ ê±°ë¶€ë˜ë©´ ì—¬ê¸°ì„œ ê±¸ë¦½ë‹ˆë‹¤.
            print(f"   â³ DB ë¶€íŒ… ëŒ€ê¸° ì¤‘... 3ì´ˆ ë’¤ ì¬ì‹œë„. (ì—ëŸ¬ì½”ë“œ: {e.args[0]})")
            time.sleep(3)
            retries -= 1
            
        except Exception as e:
            print(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì—ëŸ¬: {e}")
            time.sleep(3)
            retries -= 1
            
    print("âŒâŒ DB ì ‘ì† ìµœì¢… ì‹¤íŒ¨. ë„ì»¤ ë¡œê·¸ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
    sys.exit(1) # ê°•ì œ ì¢…ë£Œ

def save_to_db(items):
    if not items:
        print("ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    print(f"\n>> DB ì €ì¥ ì‹œì‘ ({len(items)}ê°œ)...")
    
    conn = None
    try:
        conn = pymysql.connect(**db_config)
        cursor = conn.cursor()

        sql = """
            INSERT INTO musinsa_item 
            (title, brand, price, img_url, category, link, ranking, like_count, rating, review_count, view_count) 
            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
        """

        for item in items:
            cursor.execute(sql, (
                item['title'], 
                item['brand'], 
                item['price'], 
                item['img_url'], 
                item['category'],
                item.get('link', '#'),
                item['ranking'],
                item['like_count'],
                item['rating'],
                item['review_count'],
                item['view_count']
            ))
        
        conn.commit()
        print(">> âœ… DB ì €ì¥ ì§„ì§œ ì™„ë£Œ!")
        
    except Exception as e:
        print(f"âŒ DB ì €ì¥ ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}")
    finally:
        if conn:
            conn.close()

if __name__ == "__main__":
    # 1. DB ì¤€ë¹„ (ì—°ê²°ë  ë•Œê¹Œì§€ ëŒ€ê¸° í›„ í…Œì´ë¸” ìƒì„±)
    init_db()

    # 2. í¬ë¡¤ë§ ì‹¤í–‰
    crawled_data = scrape_musinsa()
    
    # 3. DB ì €ì¥ ì‹¤í–‰
    save_to_db(crawled_data)