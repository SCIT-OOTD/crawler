from playwright.sync_api import sync_playwright
import sys
import time
import re
import pymysql

# 1. DB ì„¤ì •
db_config = {
    'host': 'mysql-container',   # docker-compose ì„œë¹„ìŠ¤ ì´ë¦„
    'user': 'root',
    'password': '1234',
    'database': 'musinsa_db',
    'port': 3306,
    'charset': 'utf8mb4',
    'cursorclass': pymysql.cursors.DictCursor
}

def scrape_musinsa():
    total_results = []
    # ì¹´í…Œê³ ë¦¬ ì •ì˜
    CATEGORY_URLS = {
        "ìƒì˜": "https://www.musinsa.com/main/musinsa/ranking?gf=A&storeCode=musinsa&sectionId=200&categoryCode=001000",
        "í•˜ì˜": "https://www.musinsa.com/main/musinsa/ranking?gf=A&storeCode=musinsa&sectionId=200&categoryCode=003000",
        "ì‹ ë°œ": "https://www.musinsa.com/main/musinsa/ranking?gf=A&storeCode=musinsa&sectionId=200&categoryCode=005000",
        "ì•„ìš°í„°": "https://www.musinsa.com/main/musinsa/ranking?gf=A&storeCode=musinsa&sectionId=200&categoryCode=002000"
    }

    print(">> [ë¬´ì‹ ì‚¬] ëŒ€ê·œëª¨ í¬ë¡¤ë§ ì‹œì‘ (ì¹´í…Œê³ ë¦¬ë³„ 100ê°œ)...", flush=True)

    with sync_playwright() as p:
        browser = p.chromium.launch(headless=True)
        # 100ê°œ ê¸ëŠ” ë™ì•ˆ íƒ€ì„ì•„ì›ƒ ë‚˜ì§€ ì•Šê²Œ ì„¤ì •
        context = browser.new_context(viewport={"width": 1920, "height": 1080})
        page = context.new_page()
        page.set_default_timeout(60000) # 60ì´ˆ

        for cat_name, cat_url in CATEGORY_URLS.items():
            print(f"\n>> ğŸš€ [{cat_name}] ë¦¬ìŠ¤íŠ¸ í™•ë³´ ì‹œì‘...", flush=True)
            try:
                page.goto(cat_url)
                time.sleep(2)

                # ---------------------------------------------------------
                # [í•µì‹¬] 100ê°œ ëª¨ì¼ ë•Œê¹Œì§€ ìŠ¤í¬ë¡¤ ë‚´ë¦¬ê¸° (ê°•ë ¥í•œ ë¡œì§)
                # ---------------------------------------------------------
                target_count = 100
                prev_count = 0
                scroll_attempts = 0
                max_attempts = 30  # ìµœëŒ€ 30ë²ˆ ìŠ¤í¬ë¡¤ ì‹œë„

                while True:
                    # í˜„ì¬ í™”ë©´ì— ë¡œë”©ëœ ìƒí’ˆ ë§í¬ ê°œìˆ˜ ì„¸ê¸° (ì¤‘ë³µ ì œê±° ì „ ë‹¨ìˆœ ê°œìˆ˜)
                    # ë¬´ì‹ ì‚¬ëŠ” í•œ ìƒí’ˆì— ë§í¬ê°€ ì—¬ëŸ¬ ê°œì¼ ìˆ˜ ìˆì–´ì„œ ë„‰ë„‰í•˜ê²Œ ë´…ë‹ˆë‹¤.
                    page.keyboard.press("End")
                    time.sleep(1.5) # ë¡œë”© ëŒ€ê¸°

                    # ì‹¤ì œ ìœ ë‹ˆí¬í•œ ìƒí’ˆ ë§í¬ ê°œìˆ˜ ê³„ì‚°
                    unique_count = page.evaluate("""() => {
                        const links = Array.from(document.querySelectorAll("a"));
                        const goodsLinks = links
                            .map(a => a.href)
                            .filter(href => (href.includes('/goods/') || href.includes('/products/')) && !href.includes('reviews'));
                        
                        // ì£¼ì†Œì—ì„œ ? ë’¤ì— íŒŒë¼ë¯¸í„° ë–¼ê³  ì¤‘ë³µ ì œê±°í•´ì„œ ìˆ«ì ì„¸ê¸°
                        const uniqueSet = new Set(goodsLinks.map(url => url.split('?')[0]));
                        return uniqueSet.size;
                    }""")
                    
                    print(f"   Now: ìƒí’ˆ {unique_count}ê°œ ë°œê²¬... (ìŠ¤í¬ë¡¤ ì¤‘)", flush=True)

                    if unique_count >= target_count:
                        print(f"   âœ… ëª©í‘œ ë‹¬ì„±! ({unique_count}ê°œ)")
                        break
                    
                    if unique_count == prev_count:
                        scroll_attempts += 1
                        if scroll_attempts >= 5: # 5ë²ˆ ì—°ì†ìœ¼ë¡œ ê°œìˆ˜ê°€ ì•ˆ ëŠ˜ì–´ë‚˜ë©´ ëìœ¼ë¡œ ê°„ì£¼
                            print("   âš ï¸ ë” ì´ìƒ ìƒí’ˆì´ ì—†ìŠµë‹ˆë‹¤.")
                            break
                    else:
                        scroll_attempts = 0 # ê°œìˆ˜ê°€ ëŠ˜ì–´ë‚¬ìœ¼ë©´ ì¹´ìš´íŠ¸ ì´ˆê¸°í™”
                    
                    prev_count = unique_count
                    
                    if scroll_attempts > max_attempts:
                        break

                # ---------------------------------------------------------
                # ë§í¬ ì¶”ì¶œ
                # ---------------------------------------------------------
                items_data = page.evaluate("""() => {
                    const data = [];
                    const links = Array.from(document.querySelectorAll("a"));
                    const productLinks = links.filter(a => 
                        (a.href.includes('/goods/') || a.href.includes('/products/')) && 
                        !a.href.includes('reviews')
                    );
                    productLinks.forEach(a => { data.push({ href: a.href }); });
                    return data;
                }""")

                # íŒŒì´ì¬ì—ì„œ ì¤‘ë³µ ì œê±°í•˜ê³  100ê°œ ìë¥´ê¸°
                target_items = []
                seen = set()
                for item in items_data:
                    url = item['href'].split('?')[0]
                    if url not in seen:
                        seen.add(url)
                        target_items.append(item)
                
                # ë”± 100ê°œë§Œ ë‚¨ê¸°ê¸°
                target_items = target_items[:100]
                print(f"   - ì‹¤ì œ ìˆ˜ì§‘í•  ë§í¬: {len(target_items)}ê°œ")

                # ---------------------------------------------------------
                # ìƒì„¸ í˜ì´ì§€ ìˆœíšŒ
                # ---------------------------------------------------------
                for idx, item in enumerate(target_items):
                    try:
                        page.goto(item['href'])
                        time.sleep(0.5) 

                        extracted = page.evaluate("""() => {
                            const getMeta = (p) => document.querySelector(`meta[property="${p}"]`)?.content || "";
                            const spans = Array.from(document.querySelectorAll('span'));

                            // í›„ê¸°
                            let reviewCnt = 0;
                            const reviewEl = spans.find(el => el.innerText.includes('í›„ê¸°') && el.className.includes('text-gray-600'));
                            if (reviewEl) reviewCnt = parseInt(reviewEl.innerText.replace(/[^0-9]/g, '')) || 0;

                            // í‰ì 
                            let ratingVal = 0.0;
                            const ratingEl = spans.find(el => el.className.includes('text-black') && /^[0-5]\\.\\d$/.test(el.innerText.trim()));
                            if (ratingEl) ratingVal = parseFloat(ratingEl.innerText) || 0.0;

                            // ì¢‹ì•„ìš”
                            let likeCnt = 0;
                            const likeEl = spans.find(el => el.className.includes('text-body_13px_med') && !el.className.includes('text-black') && /^\\d+$/.test(el.innerText.trim()));
                            if (likeEl) likeCnt = parseInt(likeEl.innerText) || 0;

                            return {
                                title: getMeta('og:title'),
                                brand: getMeta('product:brand'),
                                img: getMeta('og:image'),
                                price: getMeta('product:price:amount'),
                                review_count: reviewCnt,
                                rating: ratingVal,
                                like_count: likeCnt
                            };
                        }""")

                        price_int = int(extracted['price']) if extracted['price'] else 0
                        
                        data = {
                            "ranking": idx + 1,
                            "brand": extracted['brand'] if extracted['brand'] else "ë¬´ì‹ ì‚¬",
                            "title": extracted['title'],
                            "price": price_int,
                            "img_url": extracted['img'],
                            "category": cat_name,
                            "link": item['href'],
                            "like_count": extracted['like_count'],
                            "rating": extracted['rating'],
                            "review_count": extracted['review_count'],
                            "view_count": 0
                        }
                        total_results.append(data)
                        
                        if (idx + 1) % 10 == 0:
                            print(f"     [{cat_name}] {idx + 1}/100 ì™„ë£Œ...")

                    except Exception as e:
                        print(f"     X ê°œë³„ ìƒí’ˆ ì—ëŸ¬: {e}")
            
            except Exception as e:
                print(f"[{cat_name}] ì¹´í…Œê³ ë¦¬ ì—ëŸ¬: {e}")

        browser.close()
    
    return total_results

def init_db():
    retries = 30
    while retries > 0:
        try:
            print(f">> DB ì ‘ì† ì‹œë„ ì¤‘... (ë‚¨ì€ ì‹œë„: {retries})")
            conn = pymysql.connect(**db_config)
            cursor = conn.cursor()
            create_table_sql = """
            CREATE TABLE IF NOT EXISTS musinsa_item (
                id INT AUTO_INCREMENT PRIMARY KEY,
                title VARCHAR(255),
                brand VARCHAR(100),
                price INT,
                img_url TEXT,
                category VARCHAR(50),
                link TEXT,
                ranking INT,
                like_count INT DEFAULT 0,
                rating FLOAT DEFAULT 0.0,
                review_count INT DEFAULT 0,
                view_count INT DEFAULT 0,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            );
            """
            cursor.execute(create_table_sql)
            conn.commit()
            print(">> âœ… DB ì—°ê²° ì™„ë£Œ!")
            conn.close()
            return
        except Exception as e:
            print(f"   â³ DB ëŒ€ê¸° ì¤‘... ({e})")
            time.sleep(3)
            retries -= 1
    sys.exit(1)

def save_to_db(items):
    if not items: return
    print(f"\n>> DB ì €ì¥ ì‹œì‘ ({len(items)}ê°œ)...")
    conn = None
    try:
        conn = pymysql.connect(**db_config)
        cursor = conn.cursor()
        sql = """
            INSERT INTO musinsa_item 
            (title, brand, price, img_url, category, link, ranking, like_count, rating, review_count, view_count) 
            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
        """
        for item in items:
            cursor.execute(sql, (
                item['title'], item['brand'], item['price'], item['img_url'], 
                item['category'], item.get('link', '#'), item['ranking'],
                item['like_count'], item['rating'], item['review_count'], item['view_count']
            ))
        conn.commit()
        print(f">> âœ… DB ì €ì¥ ì™„ë£Œ!")
    except Exception as e:
        print(f"âŒ ì €ì¥ ì—ëŸ¬: {e}")
    finally:
        if conn: conn.close()

if __name__ == "__main__":
    # í˜¹ì‹œ ì´ íŒŒì¼ì„ ì§ì ‘ ì‹¤í–‰í•  ë•Œë¥¼ ëŒ€ë¹„í•´ ë‘ 
    init_db()
    crawled_data = scrape_musinsa()
    save_to_db(crawled_data)