from playwright.sync_api import sync_playwright
import sys
import time
import re
import pymysql

# 1. DB ì„¤ì •
db_config = {
    'host': 'mysql-container',   # docker-compose ì„œë¹„ìŠ¤ ì´ë¦„
    'user': 'root',
    'password': '1234',          # docker-compose ë¹„ë²ˆ ì¼ì¹˜ í™•ì¸
    'database': 'musinsa_db',    # DB ì´ë¦„ ì¼ì¹˜ í™•ì¸
    'port': 3306,
    'charset': 'utf8mb4',
    'cursorclass': pymysql.cursors.DictCursor
}

def parse_korean_number(text):
    if not text: return 0
    text = str(text).strip()
    multiplier = 1
    if 'ë§Œ' in text:
        multiplier = 10000
        text = text.replace('ë§Œ', '')
    elif 'ì²œ' in text:
        multiplier = 1000
        text = text.replace('ì²œ', '')
    clean_num = re.sub(r"[^0-9.]", "", text)
    if clean_num:
        try:
            return int(float(clean_num) * multiplier)
        except:
            return 0
    return 0

def scrape_musinsa():
    total_results = []
    CATEGORY_URLS = {
        "ìƒì˜": "https://www.musinsa.com/main/musinsa/ranking?gf=A&storeCode=musinsa&sectionId=200&categoryCode=001000",
        "í•˜ì˜": "https://www.musinsa.com/main/musinsa/ranking?gf=A&storeCode=musinsa&sectionId=200&categoryCode=003000",
        "ì‹ ë°œ": "https://www.musinsa.com/main/musinsa/ranking?gf=A&storeCode=musinsa&sectionId=200&categoryCode=005000",
        "ì•„ìš°í„°": "https://www.musinsa.com/main/musinsa/ranking?gf=A&storeCode=musinsa&sectionId=200&categoryCode=002000"
    }

    print(">> [ë¬´ì‹ ì‚¬] í†µí•© í¬ë¡¤ë§ ì‹œì‘...", flush=True)

    with sync_playwright() as p:
        browser = p.chromium.launch(headless=True)
        page = browser.new_page()

        for cat_name, cat_url in CATEGORY_URLS.items():
            print(f"\n>> ğŸš€ [{cat_name}] ìˆ˜ì§‘ ì‹œì‘...", flush=True)
            try:
                page.goto(cat_url, timeout=60000)
                time.sleep(2)

                # ìŠ¤í¬ë¡¤
                for _ in range(3): 
                    page.keyboard.press("PageDown")
                    time.sleep(1)
                
                # ë§í¬ ìˆ˜ì§‘
                items_data = page.evaluate("""() => {
                    const data = [];
                    const links = Array.from(document.querySelectorAll("a"));
                    const productLinks = links.filter(a => 
                        (a.href.includes('/goods/') || a.href.includes('/products/')) && 
                        !a.href.includes('reviews')
                    );
                    // í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ 5ê°œë§Œ ìˆ˜ì§‘
                    productLinks.slice(0, 5).forEach(a => { data.push({ href: a.href }); });
                    return data;
                }""")

                # ì¤‘ë³µ ì œê±°
                target_items = []
                seen = set()
                for item in items_data:
                    url = item['href'].split('?')[0]
                    if url not in seen:
                        seen.add(url)
                        target_items.append(item)

                # ìƒì„¸ í˜ì´ì§€ ì´ë™
                for idx, item in enumerate(target_items):
                    try:
                        page.goto(item['href'], timeout=60000)
                        time.sleep(1) 

                        # â–¼ [ìˆ˜ì •ë¨] ìƒì„¸ ì •ë³´(í›„ê¸°, í‰ì , ì¢‹ì•„ìš”) ê¸ì–´ì˜¤ëŠ” ë¡œì§ ì¶”ê°€
                        extracted = page.evaluate("""() => {
                            // 1. ê¸°ë³¸ ë©”íƒ€ ì •ë³´ (ì œëª©, ë¸Œëœë“œ, ì´ë¯¸ì§€, ê°€ê²©)
                            const getMeta = (p) => document.querySelector(`meta[property="${p}"]`)?.content || "";
                            
                            // 2. [ì‚¬ìš©ì ì œë³´ ê¸°ë°˜] ì •í™•í•œ íƒœê·¸ ì°¾ê¸°
                            const spans = Array.from(document.querySelectorAll('span'));

                            // (1) í›„ê¸° ì°¾ê¸°: "í›„ê¸°"ë¼ëŠ” ê¸€ìê°€ ìˆê³  + íšŒìƒ‰ ê¸€ì”¨(text-gray-600)ì¸ ê²ƒ
                            // ì˜ˆ: <span class="... text-gray-600 ...">í›„ê¸° 11ê°œ</span>
                            let reviewCnt = 0;
                            const reviewEl = spans.find(el => el.innerText.includes('í›„ê¸°') && el.className.includes('text-gray-600'));
                            if (reviewEl) {
                                reviewCnt = parseInt(reviewEl.innerText.replace(/[^0-9]/g, '')) || 0;
                            }

                            // (2) í‰ì  ì°¾ê¸°: ê²€ì€ ê¸€ì”¨(text-black)ì´ë©´ì„œ + ì†Œìˆ˜ì (.)ì´ ìˆëŠ” ìˆ«ì
                            // ì˜ˆ: <span class="... text-black ...">4.9</span>
                            let ratingVal = 0.0;
                            const ratingEl = spans.find(el => 
                                el.className.includes('text-black') && 
                                /^[0-5]\.\d$/.test(el.innerText.trim()) // "4.9" ê°™ì€ í˜•íƒœì¸ì§€ í™•ì¸
                            );
                            if (ratingEl) {
                                ratingVal = parseFloat(ratingEl.innerText) || 0.0;
                            }

                            // (3) ì¢‹ì•„ìš” ìˆ˜ ì°¾ê¸°: "text-body_13px_med" í´ë˜ìŠ¤ì´ë©´ì„œ + ê·¸ëƒ¥ ì •ìˆ˜ ìˆ«ìë§Œ ìˆëŠ” ê²ƒ
                            // (í‰ì ì€ ì†Œìˆ˜ì ì´ ìˆì–´ì„œ ì œì™¸ë˜ê³ , í›„ê¸°ëŠ” ê¸€ìê°€ ìˆì–´ì„œ ì œì™¸ë¨)
                            let likeCnt = 0;
                            const likeEl = spans.find(el => 
                                el.className.includes('text-body_13px_med') &&   // í°íŠ¸ í´ë˜ìŠ¤ ì¼ì¹˜
                                !el.className.includes('text-black') &&          // í‰ì (ê²€ì€ìƒ‰) ì•„ë‹˜
                                /^\d+$/.test(el.innerText.trim())                // ì˜¤ì§ ìˆ«ìë§Œ ìˆì–´ì•¼ í•¨ (ì˜ˆ: "254")
                            );
                            if (likeEl) {
                                likeCnt = parseInt(likeEl.innerText) || 0;
                            }

                            return {
                                title: getMeta('og:title'),
                                brand: getMeta('product:brand'),
                                img: getMeta('og:image'),
                                price: getMeta('product:price:amount'),
                                review_count: reviewCnt,
                                rating: ratingVal,
                                like_count: likeCnt
                            };
                        }""")

                        price_int = int(extracted['price']) if extracted['price'] else 0
                        
                        # â–¼ [ìˆ˜ì •ë¨] 0 ëŒ€ì‹  ì‹¤ì œ ê¸ì–´ì˜¨ ê°’ ë„£ê¸°
                        data = {
                            "ranking": idx + 1,
                            "brand": extracted['brand'] if extracted['brand'] else "ë¬´ì‹ ì‚¬",
                            "title": extracted['title'],
                            "price": price_int,
                            "img_url": extracted['img'],
                            "category": cat_name,
                            "link": item['href'],
                            "like_count": extracted['like_count'],     # ì‹¤ì œ ê°’
                            "rating": extracted['rating'],             # ì‹¤ì œ ê°’
                            "review_count": extracted['review_count'], # ì‹¤ì œ ê°’
                            "view_count": 0  # ì¡°íšŒìˆ˜ëŠ” ìˆ˜ì§‘ ë¶ˆê°€(ë³´í†µ 0)
                        }
                        total_results.append(data)
                        print(f"  - ìˆ˜ì§‘ì„±ê³µ: {data['title'][:10]}... (í›„ê¸°:{data['review_count']}ê°œ, í‰ì :{data['rating']})")

                    except Exception as e:
                        print(f"  - ê°œë³„ ìƒí’ˆ ì—ëŸ¬: {e}")
            
            except Exception as e:
                print(f"[{cat_name}] ì¹´í…Œê³ ë¦¬ ì—ëŸ¬: {e}")

        browser.close()
    
    return total_results

def init_db():
    retries = 30
    while retries > 0:
        try:
            print(f">> DB ì ‘ì† ì‹œë„ ì¤‘... (ë‚¨ì€ ì‹œë„: {retries})")
            conn = pymysql.connect(**db_config)
            cursor = conn.cursor()
            
            create_table_sql = """
            CREATE TABLE IF NOT EXISTS musinsa_item (
                id INT AUTO_INCREMENT PRIMARY KEY,
                title VARCHAR(255),
                brand VARCHAR(100),
                price INT,
                img_url TEXT,
                category VARCHAR(50),
                link TEXT,
                ranking INT,
                like_count INT DEFAULT 0,
                rating FLOAT DEFAULT 0.0,
                review_count INT DEFAULT 0,
                view_count INT DEFAULT 0,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            );
            """
            cursor.execute(create_table_sql)
            conn.commit()
            print(">> âœ… DB ì—°ê²° ë° í…Œì´ë¸” í™•ì¸ ì™„ë£Œ! (ì„±ê³µ)")
            conn.close()
            return
            
        except pymysql.err.OperationalError as e:
            print(f"   â³ DB ë¶€íŒ… ëŒ€ê¸° ì¤‘... 3ì´ˆ ë’¤ ì¬ì‹œë„. (ì—ëŸ¬ì½”ë“œ: {e.args[0]})")
            time.sleep(3)
            retries -= 1
            
        except Exception as e:
            print(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì—ëŸ¬: {e}")
            time.sleep(3)
            retries -= 1
            
    print("âŒâŒ DB ì ‘ì† ìµœì¢… ì‹¤íŒ¨. ë„ì»¤ ë¡œê·¸ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")
    sys.exit(1)

def save_to_db(items):
    if not items:
        print("ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    print(f"\n>> DB ì €ì¥ ì‹œì‘ ({len(items)}ê°œ)...")
    
    conn = None
    try:
        conn = pymysql.connect(**db_config)
        cursor = conn.cursor()

        sql = """
            INSERT INTO musinsa_item 
            (title, brand, price, img_url, category, link, ranking, like_count, rating, review_count, view_count) 
            VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
        """

        for item in items:
            cursor.execute(sql, (
                item['title'], 
                item['brand'], 
                item['price'], 
                item['img_url'], 
                item['category'],
                item.get('link', '#'),
                item['ranking'],
                item['like_count'],
                item['rating'],
                item['review_count'],
                item['view_count']
            ))
        
        conn.commit()
        print(">> âœ… DB ì €ì¥ ì§„ì§œ ì™„ë£Œ!")
        
    except Exception as e:
        print(f"âŒ DB ì €ì¥ ì¤‘ ì—ëŸ¬ ë°œìƒ: {e}")
    finally:
        if conn:
            conn.close()

if __name__ == "__main__":
    init_db()
    crawled_data = scrape_musinsa()
    save_to_db(crawled_data)